shared_decoding:
  llm_mode: openai
  provider: mock
  model_name: gpt-4o-mini
  temperature: 0.2
  top_p: 1.0
  max_tokens: 300

baseline:
  name: baseline_direct
  prompt_name: baseline_direct_answer

enhanced:
  name: enhanced_rag_guardrail
  prompt_name: rag_with_safety_guardrails
  knowledge_base_path: data/raw/knowledge_base.json
  retrieval_top_k: 2
